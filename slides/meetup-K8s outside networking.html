<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Kubernetes networking and the outside world</title>

		<meta name="description" content="A presentation of Kubernetes networking models for communication with outside world on On-Premises setups.">
		<meta name="author" content="Laurent CORBES <laurent.corbes@enix.fr>">


		<link rel="stylesheet" href="reveal.js/css/reveal.css">
		<!-- <link rel="stylesheet" href="reveal.js/css/theme/solarized.css"> -->
		<link rel="stylesheet" href="enix.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>

		<div class="reveal">
			<div class="slides">

				<section>
					<h3>Kubernetes networking and the outside world</h3>
					<h5>a story about how K8S chats with its friends</h5>
					<p>
						<small>Laurent CORBES (<a href="http://enix.io/">Enix</a>) (@lcaflc)</small>
					</p>
				</section>


				<section>
					<h3>Who's ENIX?</h3>
					<h5>A team of experts who can help you with:</h5>
					<small>
						<ul>
							<li>
								Container Orchestration
								<br/>
								(consulting, training, managed Kubernetes hosting)
							</li>
							<li>Network
								<br/>
								(our teams have built CDNs and dark fiber networks)
							</li>
							<li>Virtualization
								<br/>
								(we were already selling Xen VMs in 2005)
							</li>
							<li>Hosting
								<br/>
							    (let's Terraform your OpenStack)
							</li>
						</ul>
					</small>
					<aside class="notes">
						(Le but c'est de faire du namedropping rapide,
						sans forcément insister sur un point ou un autre.)
						<br/>
						Peut-être dire un truc du genre "on prend des
						technologies ont la réputation d'être compliquées,
						et on vous aide à extraire la partie vraiment utile
						pour vos projets pour que ça vous fasse gagner
						du temps et de l'argent"
						<br />
						On automatise tout ce qui est possible. (Terraform ansible)
					</aside>
				</section>

				<section>
					<h3>Outline</h3>
					<ul>
						<li>K8S networking model</li>
						<li>Custom Integration</li>
						<li>Kube-Router</li>
					</ul>
					<aside class="notes">
						Presentation des sections
					</aside>
				</section>

				<section>
					<h3>K8S networking model</h3>
					<ul>
						<li class="fragment">direct containers and nodes communication </li>
						<li class="fragment">Containers see their own IP</li>
						<li class="fragment">IP per Pod</li>
						<li class="fragment">Cluster network</li>
					</ul>

					<aside class="notes">
						K8s force a ce que tous les elements d'un cluster puissent communiquer a plat (directement dans le sens bidirectionnel sans NAT ou proxy qui change l'ip visible d'un des 2).
						<br/>
						Un container a une IP unique qui lui est attache et qu'il utilise lui meme. (ifconfig dans le container donne son ip que tout le monde voit)
						<br/>
						L'unite atomique de k8s etant le pod. en fait tous les containers d'un POD sont lie par cette IP unique. Ils doivent donc se partager les ports disponible. tous peuvent se parler en localhost. Cela mimic le fonctionnement d'une VM.
						<br/>
						La plupart des implementations necessite de dedier un IP range. Celui ci est gere (decoupe, alloue, IPAM) par le network plugin.
					</aside>
				</section>


				<section>
					<section>
						<h5>Pod to Pod network communication:</h5>
						<ul>
							<li class="fragment"><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/">Plugin driven</a></li>
							<li class="fragment">Multiple providers</li>
							<li class="fragment">Almost plug and play</li>
						</ul>
						<aside class="notes">
							Le networking model Pod to Pod de kubernetes est maintenant mature,
							<br/>
							le systeme de plugin permet de facilement implementer ce que l'on veut.
						</aside>
					</section>
					<section>
						<p>On all setups there is an <em>"easy"</em> solution.</p>
						<ul>
							<li class="fragment"><a href="https://www.weave.works/oss/net/">Weave Net</a></li>
							<li class="fragment"><a href="https://github.com/coreos/flannel#flannel">Flannel</a></li>
							<li class="fragment"><a href="https://docs.projectcalico.org/v3.2/introduction/">Calico</a></li>
						</ul>

						<aside class="notes">
							quelle que soit le besoin on trouvera une solution. Ca se change tres facilement, ce n'est plus un probleme aujourd'hui.
							<br/>
							Weave Net: simple et fonctionne partout car base sur l'encapsulation du reseau entre tous les nodes.
							<br/>
							Flannel: Routage simple entre les nodes. decoupe le CIDR en subnetworks associe a chaque node.
							<br/>
							Calico: Highly scalable, BGP, Network policies. les network policy permettent de filtrer le traffic entre les pods, Certains l'implement et d'autre non.
						</aside>
					</section>
				</section>


				<section>
					<section>
					<h5>External network communication:</h5>
					<ul>
						<li class="fragment">Inbound: External to K8s Services</li>
						<li class="fragment">Outbound: Pods to external</li>
						<li class="fragment">External to Pods (Why not !)</li>
					</ul>

					<aside class="notes">
						La communication entre kubernetes et l'exterieur comprend 2 type de communications.
						<br/>
						La communication vers les services qui tournent dans K8s.
						<br/>
						vers l'externe permet d'aller vers des ressources vers internet, mais aussi des besoins de DB / services legacy dans des DMZ protege
						<br />
						external to pods vous considerez que ce n'est pas possible a cause de la frontiere mise en place en general. mais c'est tout a fait possible.
					</aside>
					</section>

					<section>
					<p>Inbound</p>
					<ul>
						<li class="fragment"><a href="https://kubernetes.io/docs/concepts/services-networking/service/">Services driven</a></li>
						<li class="fragment">ClusterIP</li>
						<li class="fragment">NodePort</li>
					</ul>

					<aside class="notes">
						Mis en place grace au systeme de service.
						<br/>
						ClusterIP permet de mapper une ip de mon cluster a un service. cool mais ip interne seulement.
						<br/>
						NodePort permet d'exposer ce service aux ips externe de mon cluster. Cela se comprend dans le monde K8s ou tous les nodes
					</aside>
					</section>

					<section>
					<p>Outbound</p>
					<ul>
						<li class="fragment">SNAT</li>
						<li class="fragment">Routing</li>
						<li class="fragment">CNI integration</li>
					</ul>

					<aside class="notes">
						En mode SNAT tout le cluster-ip-network tres simple a mettre en place. mais tres complique de filtrer dans un firewall / DMZ quelle ressource accede a la DB.
						<br/>
						En mode routage simple, possobilite de filtrage plus fin, mais si routes dynamique maintenance sur les nodes a faire.
						<br/>
						Certains CNI specialise fournissent une integration dans les modeles existant (Nuage, OVS, Calico)
					</aside>
					</section>
				</section>


				<section>
					<p>
						Standard modules not sufficient
					</p>
					<p><strong>
						Need some extra integration
					</strong>	</p>
					<aside class="notes">
						Traffic directement sur le les nodes problemes:
						plusieurs services que je veux avoir sur le meme port standard pas possible.
						redondance ? dns ?
						port 22 deja pris sur les nodes par ex.
						<br />
						Il est necessaire de mettre en place de la glue et de l'integration entre les environnements exterieur specifique et k8s.
						<br/>
						Les possobilites sont trop nombreuses pour etre native a k8s.
					</aside>
				</section>

				<section>
					<h3>Super Glue</h3>
				</section>

				<section>
					<h5>Cloud Providers world</h5>
					<ul>
						<li>K8s as a Service</li>
						<li>CNI driver</li>
						<li>Services load balancer</li>
					</ul>

					<aside class="notes">
						Regarder ce que les gros acteurs font.
						<br/>
						Dans le cas d'un K8s as a service tout est integre par le cloud provider.
						<br/>
						Integration d'un CNI driver qui permet de se plug nativement au networking model du provider.
						<br/>
						Creation d'un ingress service de type LoadBalancer. je cree le service et quelques minutes plutart magiquement j'ai mon service qui est expose sur internet.
					</aside>
				</section>

				<section>
					<section>
						<h5>On Premise subworld</h5>
						<p>DiY</p>
						<aside class='notes'>
							Dans le monde maintenant underground du On premise, il faut tout faire soit meme en utilisant les briques les plus malignes possible en fonction de ses besoins.
						</aside>
					</section>

					<section>
						<p>OpenStack</p>
						<p><small>
							The Clone Wars
						</small></p>
						<ul>
							<li class="fragment">Integration standard</li>
							<li class="fragment">Neutron LBaaS</li>
							<li class="fragment">Layer2 networking</li>
						</ul>

						<aside class="notes">
							Si on a la "chance" d'avoir une plateforme OpenStack il faut capitaliser sur l'existant.
							<br/>
							Utilisation du service de loadbalancing neutron. avec le plugin k8s dedie cela permet de piloter le LBaaS et allouer des ips de services directement depuis la configuration k8s. Permet de profiter de la couche d'abstraction des couches openstack pour systemes externe.
							<br/>
							Utilisation du layer2 routing et allocation d'un cluster-network qui correspond au private network openstack.
						</aside>
				  </section>

					<section>
						<p>Self made Load Balancer</p>
						<p><small>
							No Pain, No Gain
						</small></p>
						<ul>
							<li class="fragment">Time consuming</li>
							<li class="fragment">Simple load balancer + NodePort</li>
							<li class="fragment">Dynamic with K8s API</li>
							<li class="fragment">Ingress Controller</li>
						</ul>

						<aside class="notes">
							On peut toujours se faire son propre load balancer. que ce soit en externe du cluster K8s ou en interne.
							<br/>
							Le resultat optinu dependra du temps investi.
							<br/>
							Le plus simple est d'exporter les services en utilisant la methode du NodePort et configurer le loadbalancer externe pour les utiliser
							<br/>
							Si besoin de dynamique faire des wrapper en utilisant de l'API k8s.
							<br />
							possobilite d'utiliser un ingress Controller. qui fourni une configuration pour des loadbalancer type nginx / traefik. mais http only
						</aside>
				  </section>

					<section>
						<p>Kube-Router</p>
						<p><small>
							Old pipes give sweetest smoke
						</small></p>
						<ul>
							<li class="fragment"><a href="https://kube-router.io/">https://kube-router.io/</a></li>
							<li class="fragment">BGP routing</li>
							<li class="fragment">IPVS loadbalancer</li>
						</ul>

						<aside class="notes">
							C'est avec les vieilles casseroles que l'on fait la meilleure soupe.
							<br/>
							C'est une combinaison des technologies BGP et ipvs. Ce ne sont pas des gros mots :)
							<br/>
							BGP c'est le protocole de routage qui fait fonctionner internet depuis quelques dizaines d'annees. Et utiliser BGP c'est profiter des capacites des routeurs existant et archi reseau actuelle.
							<br/>
							IPVS quand a lui est utilise dans les load balancers linux
						</aside>
					</section>
				</section>

				<section>
					<h3>Kube-Router</h3>
					<aside class="notes">
						Comme on peut s'en douter Kube-Router est notre choix de predilection.
					</aside>
				</section>
				<section>
					<section>
						<h5>Pod to Pod networking</h5>
						<ul>
							<li class="fragment">Fully Dynamic</li>
							<li class="fragment">Fully meshed</li>
							<li class="fragment">No NAT</li>
							<li class="fragment">Network Policy</li>
						</ul>
						<aside class="notes">
							Grace a BGP tout le routage interne au cluster est dynamique. Lors d'ajout de nodes le routage est automatiquement propage a tous les autre nodes.
							<br/>
							Le reseau est completement meshed. Tous les containers et nodes peuvent se parler entre eux sans limitations et en un seul hop.
							<br/>
							Il y a aucun NAT, toutes les connections sont directe et les ips vu partout dans le reseau sont unique a un composant (node, container, service.) On casse donc la frontiere entre le cluster kubernetes et le reste du monde. On integre le cluster a notre reseau existant.
							<br/>
							Network Policy base sur iptables
						</aside>
					</section>
					<section>
						<img data-src="kube-router pod2pod1.png" />
					</section>
					<section>
						<img data-src="kube-router pod2pod.png" />
					</section>

					<section>
						<h5>Services </h5>
						<ul>
							<li class="fragment">Dynamic Loadbalancing</li>
							<li class="fragment">L4 TCP/UDP</li>
							<li class="fragment">DSR support</li>
						</ul>
						<aside class="notes">
							Supporte bien evidemment toute la dynamique des Pods par services en utilisant l'API k8s native. plusieurs modes de balancing suppporte (less used, equal, weight)
							<br/>
							IPVS ne supporte que le niveau 4 en mode TCP ou UDP. Il n'y a pas de niveau 7 http ni SSL
							<br/>
							Support le Direct Server Return. Tres interessant pour les services necessitant beaucoup de bande passante descendante. Quand j'ai un serveur qui envoie un flux video, le flux est envoye directement au client sans repasser par le load balancer.
						</aside>
					</section>
					<section>
						<img data-src="kube-router services1.png" />
					</section>
					<section>
						<img data-src="kube-router services2.png" />
					</section>
					<section>
						<img data-src="kube-router services.png" />
					</section>

					<section>
						<h5>BGP advertisement</h5>
						<ul>
							<li class="fragment">Any BGP router support</li>
							<li class="fragment">Cluster network and pod CIDRs</li>
							<li class="fragment">Services ClusterIP / External IP</li>
							<li class="fragment">ECMP</li>
						</ul>
						<aside class="notes">
							C'est la que ca devient interessant.
							<br/>
							Supporte de peerer avec n'importe quel router BGP. Peut etre un node linux de routage quagga, zebra, goBGP, bird. un routeur coeur de reseau cisco,juniper,... ou un switch de feuille sur un DC en mode layer 3.
							<br/>
							Il exporte a ce routeur le routage interne des pods pour chaque node. Cela permet un routage direct entre le coeur de reseau et les nodes donc sans perte de performance. Et permet donc aux pods de se connecter en natif a un element externe au cluster. (legacy DB)
							<br/>
							Et ca marche pareil avec les ip de service defini par ClusterIP. elle sont elle aussi exporte en tant que /32 et ip anycast par chacun des nodes.
							<br/>
							Cela permet de faire du load balancing ECMP entre les nodes pour l'acces au service. et ainsi scale naturellement. La seule limite est la capacite ECMP du routeur au dessus du cluster.
						</aside>
					</section>
					<section>
						<img data-src="kube-router external1.png" />
					</section>
					<section>
						<img data-src="kube-router external2.png" />
					</section>
					<section>
						<img data-src="kube-router external3.png" />
					</section>
					<section>
						<img data-src="kube-router external.png" />
					</section>

				</section>

				<section>
					<h3>This is the End</h3>
					<ul>
						<li>On cloud is easy</li>
						<li>But on premise is possible</li>
					</ul>
					<aside class="notes">
						Faire du K8S chez les cloud providers. c'est facile, mais opaque. c'est une blackbox sur le fonctionnement et au sens reseau on ne vois rien de l'exterieur
						<br />
						On premise il y a du boulot en plus. mais c'est faisable. grace aux projets kube-Router et un peu de graisse de coude on arrive a integrer un cluster Kubernetes de maniere transparente dans un SI existant.
						<br />
						On est pas oblige d'aller chez les cloud providers.
					</aside>
				</section>

				<section>
					<h3>Formation Kubernetes</h3>
					<small><p>
						Enix propose une formation <em>Déployer ses applications avec Kubernetes</em>.
					</p>
					<p>
						17/18 et 20/21 septembre 2018 à Paris
					</p>
					<p>
						<a href="https://enix.io/fr/services/formation/deployer-ses-applications-avec-kubernetes/">https://enix.io/fr/services/formation/deployer-ses-applications-avec-kubernetes/</a>
						<br />
						Contact: <a href="mailto:formation@enix.fr">formation@enix.io</a>
					</p>
					</small>
					<aside class="notes">
						Si vous voulez comprendre en detail comment tout cela fonctionne venez a notre formation
						<br />
						La premiere session est pleine mais il reste quelques places pour la deuxieme.
					</aside>
				</section>

			</div>
		</div>


		<script src="reveal.js/lib/js/head.min.js"></script>
		<script src="reveal.js/js/reveal.js"></script>


		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				slideNumber: true,
				slideNumber: 'c/t',
				showSlideNumber: 'speaker',

				defaultTiming: 90,
				dependencies: [
					// { src: 'reveal.js/plugin/markdown/marked.js' },
					// { src: 'reveal.js/plugin/markdown/markdown.js' },
					{ src: 'reveal.js/plugin/notes/notes.js', async: true },
					{ src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
